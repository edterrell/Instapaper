{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e47113-559c-4d5d-a8a2-078e4e4b4671",
   "metadata": {},
   "source": [
    "### Instapaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbffca9f-ecee-4142-bbc0-ba4e9d064eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/edwardterrell/opt/anaconda3/envs/scrape/bin/python'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import re\n",
    "# from dateutil import parser\n",
    "# import pandas as pd\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv\n",
    "import time\n",
    "#time.sleep(2)\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d9277f7-57c3-4777-88eb-00f61efb2906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/edwardterrell/Desktop/Training/kindle_highlights/instapaper'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7642509c-38c1-47f1-8864-a7d9d089f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept the url and output the table for a state\n",
    "# url = 'https://www.instapaper.com'\n",
    "# response = requests.get(url)\n",
    "# print(response.status_code)    #200 = success\n",
    "# page = response.text \n",
    "# soup = bs(page)\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0bf605fd-b1a4-4a59-b4ed-62773466c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb8bd615-9e9e-4cc1-9924-8bb683f7a25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edterrell@comcast.net givsiv-wacxaH-6kaqky\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "base_path = Path.home() / \"bin\" / \"passwords\"\n",
    "with open(base_path / \"instapaper_username.txt\", \"r\") as f:\n",
    "    username = f.read().strip()\n",
    "with open(base_path / \"instapaper_password.txt\", \"r\") as f:\n",
    "    password = f.read().strip()\n",
    "\n",
    "# print(username, password)  # Just for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "427c9852-d4ea-4fcf-a53f-8fee277cb86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://blog.instapaper.com', 'http://twitter.com/instapaper', 'https://www.facebook.com/instapaperholdings', 'http://blog.instapaper.com', 'http://twitter.com/instapaper', 'https://www.facebook.com/instapaperholdings', 'http://neohumanism.org/p/pa/paradox.html', 'http://www.cs.auckland.ac.nz/~chaitin/georgia.html', 'http://www.leydesdorff.net/vonneumann/', 'http://news.yahoo.com/us-wealth-gap-between-young-old-widest-ever-050259922.html', 'http://www.loebner.net/Prizef/TuringArticle.html', 'http://www.princeton.edu/~hos/Mahoney/articles/huygens/timelong/timelong.html', 'http://demonstrations.wolfram.com/PredatorPreyEcosystemARealTimeAgentBasedSimulation/', 'http://demonstrations.wolfram.com/GarbageCollectionByAnts/', 'http://en.wikipedia.org/wiki/United_States_housing_market_correction', 'http://online.wsj.com/article/SB122212948811465427.html', 'http://www.nybooks.com/blogs/nyrblog/2011/jul/13/why-fannie-and-freddie-are-not-blame-crisis/', 'http://www.investopedia.com/articles/economics/09/lehman-brothers-collapse.asp#axzz24N7q9V6u', 'http://onlinelibrary.wiley.com/doi/10.1002/cncr.21822/full', 'http://www.bloomberg.com/news/2012-09-12/u-s-poverty-rate-stays-at-almost-two-decade-high-income-falls.html', 'http://en.wikipedia.org/wiki/Emmanuel_Saez', 'http://en.wikipedia.org/wiki/Unconscious_Thought_Theory', 'http://oregonstate.edu/instruct/anth484/minwage.html', 'http://project.cyberpunk.ru/lib/', 'http://www.goodreads.com/book/show/289991.Black_Rain', 'http://en.wikipedia.org/wiki/Enigma_machine', 'http://www.cs.trincoll.edu/~crypto/historical/alberti.html', 'http://greenteapress.com/complexity/html/thinkcomplexity012.html', 'http://tech.mit.edu/V123/N8/8voting.8n.html', 'http://www.animations.physics.unsw.edu.au/jw/foucault_pendulum.html', 'http://greenteapress.com/complexity/html/thinkcomplexity010.html', 'http://www-personal.umich.edu/~axe/research_papers.html', 'http://www.poetryfoundation.org/poem/175142', 'http://www.bccresearch.com/report/physical-vapor-deposition-pvd-global-markets-mfg015e.html', 'http://gcn.com/microsites/2012/snapshot-managing-big-data/01-big-data-techniques.aspx', 'http://www.wired.com/magazine/2011/08/st_equation_rainbows/', 'http://www.smithsonianmag.com/people-places/Why-Are-Finlands-Schools-Successful.html?c=y&story=fullstory', 'http://www.vertex42.com/ExcelArticles/mc/NormalDistribution-Excel.html', 'http://resources.esri.com/help/9.3/arcgisengine/java/gp_toolref/spatial_statistics_toolbox/what_is_a_z_score_what_is_a_p_value.htm', 'http://en.wikipedia.org/wiki/Grellingâ€“Nelson_paradox', 'http://allrecipes.com/Recipe/pumpkin-gingerbread/detail.aspx', 'http://www.kingarthurflour.com/recipes/pumpkin-gingerbread-with-orange-glaze-recipe', \"http://en.wikipedia.org/wiki/Snell's_law\", 'http://users.ox.ac.uk/~jrlucas/mmg.html', 'http://users.ox.ac.uk/~jrlucas/Godel/brighton.html', 'http://www.codesandciphers.org.uk/virtualbp/poles/poles.htm', 'https://www.instapaper.com/archive/2', 'https://srv.carbonads.net/ads/click/x/GTND427WF6YDC27ECWBLYKQUCEAIP5QICV7DEZ3JCABDL27JCK7DVK3KCWBD623LCEAD62QLCY7I52JWCYYIC27KC6SIV5QECEBIKK3EHJNCLSIZ', 'https://srv.carbonads.net/ads/click/x/GTND427WF6YDC27ECWBLYKQUCEAIP5QICV7DEZ3JCABDL27JCK7DVK3KCWBD623LCEAD62QLCY7I52JWCYYIC27KC6SIV5QECEBIKK3EHJNCLSIZ', 'http://carbonads.net/?utm_source=wwwinstapapercom&utm_medium=ad_via_link&utm_campaign=in_unit&utm_term=carbon']\n"
     ]
    }
   ],
   "source": [
    "# Start Safari (or Chrome)\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "driver.get(\"https://www.instapaper.com/user/login\")\n",
    "username_field = driver.find_element(By.ID, \"username\")\n",
    "password_field = driver.find_element(By.ID, \"password\")\n",
    "\n",
    "# Fill in login form\n",
    "username_field.send_keys(username)\n",
    "time.sleep(1)\n",
    "password_field.send_keys(password)\n",
    "password_field.send_keys(Keys.RETURN)\n",
    "\n",
    "# Wait for redirect\n",
    "time.sleep(3)\n",
    "\n",
    "# Go to archive and grab links\n",
    "driver.get(\"https://www.instapaper.com/archive\")\n",
    "time.sleep(5)\n",
    "html = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = [a['href'] for a in soup.find_all('a', href=True)]  # <-- uncommented\n",
    "clean_links = [link for link in links if link.startswith(\"http\")]\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print(clean_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f6bd069-aaf5-44b3-99b6-35bd4e534580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine all of soup in a file 'all_soup.html'\n",
    "with open(\"all_soup.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf59e840-4952-4ff8-b1ed-042431e6c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a txt file with urls - one per line\n",
    "# FILENAME: filtered_links.txt\n",
    "\n",
    "import csv\n",
    "\n",
    "# instapaper_clean_links is a temp file; only to create filtered_links(the variable)\n",
    "with open(\"instapaper_clean_links.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"URL\"])\n",
    "    for url in clean_links:\n",
    "        writer.writerow([url])  # wrap url in a list!\n",
    "\n",
    "# Filter out links containing \"instapaper\" or \"ads/click\"\n",
    "filtered_links = [\n",
    "    url for url in clean_links\n",
    "    if 'instapaper' not in url and 'ads/click' not in url\n",
    "]\n",
    "\n",
    "# Save to a plain text file, one URL per line\n",
    "with open(\"filtered_links.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for url in filtered_links:\n",
    "        f.write(url + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faf9a50b-9c26-4dc4-90e5-092c01f1d0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert plain text URLs to a clickable HTML file:\n",
    "# FILENAME: clickable_links.html\n",
    "\n",
    "# Open the input file with your filtered links\n",
    "with open(\"filtered_links.txt\", \"r\") as infile:\n",
    "    urls = [line.strip() for line in infile if line.strip()]\n",
    "\n",
    "# Create an HTML file with clickable links\n",
    "with open(\"clickable_links.html\", \"w\") as outfile:\n",
    "    outfile.write(\"<!DOCTYPE html>\\n<html>\\n<body>\\n<h2>Clickable Links</h2>\\n<ul>\\n\")\n",
    "    for url in urls:\n",
    "        outfile.write(f'  <li><a href=\"{url}\" target=\"_blank\">{url}</a></li>\\n')\n",
    "    outfile.write(\"</ul>\\n</body>\\n</html>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb09ce2-df22-4813-bfe6-d540325fd10b",
   "metadata": {},
   "source": [
    "### program ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52f1830-e8ec-4af7-90a5-e4707eb55ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b465d32-5337-4baa-b58c-b345a96e5ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596e0a7-ccc8-4735-af0a-66d0cc8187bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a38cb-9bde-4a64-8951-9d242771c05f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9c76e-a260-4aa5-a255-a90c72af9a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "093a6a53-38c2-40ea-8d4e-3b2b3e086f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-01 14:30:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 6, 1, 14, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MORE FORGIVING\n",
    "# date_admitted = dateutil.parser.parse(date_admitted_str)\n",
    "dt = parser.parse(\"June 1st, 2025 2:30 PM\")\n",
    "print(dt)\n",
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b62fc2b-b960-4f76-81e9-83998437daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2025, 6, 1, 0, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MUST KNOW the expected format\n",
    "from datetime import datetime\n",
    "date_str = \"June 1, 2025\"\n",
    "datetime.strptime(date_str, \"%B %d, %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40fed25-0bf1-41d8-949d-7e13ce146ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('div',class_ ='title_meta')\n",
    "\n",
    "soup.find_all(class_ ='title_meta')\n",
    "\n",
    "soup.find_all('a',class_='js_domain_linkout')\n",
    "\n",
    "today_links = [link['href'] for link in today_div.find_all('a')]\n",
    "\n",
    "intsa = open('https://www.instapaper.com./archive').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1700b253-fee6-4a52-b881-1463c2b11f44",
   "metadata": {},
   "source": [
    "### Using regex and the DOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dd90e9-f3aa-4af1-8605-425392df4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = re.compile('Admitted')\n",
    "soup.find(text=adm)\n",
    "# This looks like a string, but it's actually a BeautifulSoup element.\n",
    "# type(soup.find(text=regex))\n",
    "# bs4.element.NavigableString"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c14907f-4f77-44aa-8471-e57735a605e8",
   "metadata": {},
   "source": [
    "For some cases it's much easier to find one element and then move up, down, or sideways within the DOM.  BeautifulSoup also allows you to look for .parent, .children, .next_sibling, .previous_sibling, etc.\n",
    "Any \"plural\" attribute such as children or siblings will return a generator. Just loop over the result or convert it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d791a-7b97-4d88-8bb7-09094942f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "adm.next.text\n",
    "adm.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9549d5-0b43-4296-b6cb-0cea56952f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_date(date_str):\n",
    "    date_str = re.match('[\\w]+\\s[\\d,\\s]+', date_str)[0]\n",
    "    return dateutil.parser.parse(date_str)\n",
    "\n",
    "def to_int(number_str):\n",
    "    number_str = re.match('[\\d,$]+', number_str)[0]\n",
    "    number_str = number_str.replace('$', '').replace(',', '')\n",
    "    return int(number_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5f2be-e488-4a5d-86e3-2fb20e5b0ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match('[\\d,$]+', area_text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae210e-4cb8-4b2e-9022-32406b7b2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plan the structure of what your going to save and how"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ad28f-f4a4-442f-b3d4-cc7bc36a9364",
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_dict = {\n",
    "    'state': state,\n",
    "    'date_admitted': date_admitted,\n",
    "    'population': population,\n",
    "    'area_sq_mi': area\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc6d1f-9f5d-4633-9075-1d7d9c0e8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_info = [penn_dict]\n",
    "penn_df = pd.DataFrame(penn_info)\n",
    "penn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879baf2-0ee2-479e-b5d9-75cd2f5349ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "penn_df.to_csv('Penn_State_Information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a7a1a-c1a7-45dd-9cfe-90575b38059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to add a col to a df\n",
    "penn_df['median_income'] = m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88016c59-599c-4e07-b28b-40d572cb2490",
   "metadata": {},
   "source": [
    "### save as functions so that they can be reused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b4237-a95a-4253-bd43-ac871c27aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accept the url and output the table for a state\n",
    "ny_url = 'https://en.wikipedia.org/wiki/New_York_(state)'\n",
    "ny_page = requests.get(ny_url).text\n",
    "ny_soup = bs(ny_page)\n",
    "\n",
    "ny_table = ny_soup.find('table')\n",
    "#ny_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c9ca8-6732-4be9-b594-09b0e1361f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af4147-70b8-4edb-b9e3-40db395fab59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23afb68-4454-4715-87b5-cd559e8003a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66243a6-9c54-4c10-8956-ba08b5c5ff5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c9413df-361b-4d1c-9248-e96bbbe734d9",
   "metadata": {},
   "source": [
    "### Data Storaage"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec273ec8-f5c1-4a3a-9b19-b7b2828390b8",
   "metadata": {},
   "source": [
    "Consider using the Feather format (provided by the feather library) \n",
    "for saving DataFrames with mixed data types, as it is designed for efficient storage and retrieval of such data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5d478-8759-4ae1-b892-f45953329c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('temp',index=False)\n",
    "df.to_excel(\"data.xlsx\", index=False)\n",
    "\n",
    "df.to_hdf(\"data.h5\", key=\"my_data\", mode=\"w\" )\n",
    "\n",
    "import sqlite3\n",
    "conn = sqlite3.connect(\"temp.db\")\n",
    "df.to_sql(\"my_table\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "import pickle\n",
    "with open(\"temp.pkl\", \"wb\") as file:\n",
    "    pickle.dump(df, file)\n",
    "\n",
    "# Feather is a lightweight and fast binary columnar storage format\n",
    "import feather\n",
    "feather.write_dataframe(df, \"temp.feather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1407a06-4ad0-47b4-826b-d81140707e8b",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc4f9a7-8ff1-451d-b160-d99bf1244ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.iana.org/domains/example']\n"
     ]
    }
   ],
   "source": [
    "# Example of basic login script with selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "# This uses the system SafariDriver\n",
    "driver = webdriver.Safari()\n",
    "\n",
    "driver.get(\"https://example.com\")\n",
    "html = driver.page_source\n",
    "\n",
    "# You can use BeautifulSoup here if needed\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = [a['href'] for a in soup.find_all('a', href=True)]\n",
    "\n",
    "print(links)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
